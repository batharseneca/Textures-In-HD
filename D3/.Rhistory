names(scaled)[5] <- "Species"
```
Next we need to split the data into training and test datasets using the same index as the linear model
```{r}
# Train-test split
train_ <- scaled[index,]
test_ <- scaled[-index,]
```
Running the actual linear model.
```{r, message=F, warning=F}
# NN training
library(neuralnet)
n <- names(train_)
f <- as.formula(paste("Species ~", paste(n[!n %in% "Species"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=c(5,3),linear.output=T)
```
This is what it looks like:
```{r}
# Creating the plot
plot(nn)
```
## Including Plots
You can also embed plots, for example:
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
clear
clear()
MSE.nn
pr.nn <- compute(nn,test_[,1:4])
test.r <- round(pr.nn$net.result,digits=0)
MSE.nn <- sum((test_[5] - test.r)^2)/nrow(test_)
MSE.nn
writeLines(paste("Mean Squared Errors\n","GLM: ",MSE.lm,"\nNeural Net: " ,MSE.nn))
test
?confustionMatrix
??confustionMatrix
install.packages("caret")
library(caret)
?confustionMatrix
library(caret)
?confusionMatrix
confusionMatrix(pr.nn)
class(pr.nn)
as.table(pr.nn)
as.table(test.r)
class(test.r)
as.table(test_[5])
test_[5]
as.table(test_[5])
class(test_[5])
as.factor(test_[5])
as.list(test_[5])
as.factor(as.list(test_[5]))
?as.list
?factor
factor(test.r)
levels(iris)
levels(iris$Species)
factor(test.r,levels=levels(iris$Species), labels=levels)
factor(test.r)
factor(test.r,levels=levels(iris$Species))
levels(iris$Species)
test.r
factor(test.r,levels=levels(iris$Species))
factor(test.r,levels=levels(iris$Species), ordered = is.ordered(test.r))
factor(test.r,levels=levels(iris$Species), ordered = T)
factor(test.r)
factor(test.r, labels=levels(iris$Species))
pred.nn.fact <- factor(test.r, labels=levels(iris$Species))
test_[5]
factor(test_[5])
class(test.r)
as.matrix(test_[5])
factor(as.matrix(test_[5]))
factor(as.matrix(test_[5]), labels=levels(iris$Species))
pred.nn.fact <- factor(test.r, labels=levels(iris$Species))
true.nn.fact <- factor(as.matrix(test_[5]), labels=levels(iris$Species))
confusionMatrix(pred.nn.fact,true.nn.fact)
library(caret)
confusionMatrix(pred.nn.fact,true.nn.fact)
install.packages('e1071', dependencies=TRUE)
confusionMatrix(pred.nn.fact,true.nn.fact)
confusion(pred.nn.fact,true.nn.fact)
library(caret)
cm <- confusion(pred.nn.fact,true.nn.fact)
cm <- confusionMatrix(pred.nn.fact,true.nn.fact)
cm
class(cm)
?confusionImage
?confusionMatrix
?confusion
??confusion
library(caret)
??confusion
plot(cm)
class(cm)
cm
cm$overall
cm
str$cm
str(cm)
cm$table
?heatmap
heatmap(cm$table)
?heatmap
heatmap(cm$table, Rowv=NA, Colv=NA)
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T)
?heatmap
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T, col = heat.colors(256))
library(ggplot2)
heatmap.2
install.packages("gplots")
library(gplots)
heatmap.2(cm$table,           # cell labeling
cellnote=cm$table,
notecex=1.0,
notecol="cyan",
na.color=par("bg"))
image(cm$table)
?image
image(cm$table, ncols=11,cex.axis=NULL,grid.col=NULL)
?image
image(cm$table, col = heat.colors(12) )
image(cm$table, col = heat.colors(4) )
image(cm$table, col = heat.colors(1) )
image(cm$table, col = heat.colors(20) )
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T, col = heat.colors(256))
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T, col = heat.colors(12))
cm$table
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T, col = heat.colors(3))
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T, col = heat.colors(100))
?heatmap
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=T, col=topo.colors(100))
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=F, col=topo.colors(100))
heatmap.2(cm$table, col=redgreen(75), scale="row",
key=TRUE, symkey=FALSE, density.info="none", trace="none", cexRow=0.5)
heatmap.2(cm$table, col=redgreen(75),
key=TRUE, symkey=FALSE, density.info="none", trace="none", cexRow=0.5)
heatmap.2(cm$table, col=redgreen(75),
key=TRUE, symkey=FALSE, density.info="none", trace="none")#, cexRow=0.5)
?read.delim
?data.frame
input <- data.frame(c(1,0,0,0,3,0,1,0,2))
input
as.matrix(c(1,0,0,0,3,0,1,0,2)
)
as.matrix(c(1,0,0,0,3,0,1,0,2),nrow=3)
?matrix
matrix(c(1,0,0,0,3,0,1,0,2),nrow=3)
input <- data.frame(matrix(c(1,0,0,0,3,0,1,0,2),nrow=3))
input
input.matrix <- data.matrix(input)
input.matrix.normalized <- normalize(input.matrix)
colnames(input.matrix.normalized) = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N")
rownames(input.matrix.normalized) = colnames(input.matrix.normalized)
confusion <- as.data.frame(as.table(input.matrix.normalized))
plot <- ggplot(confusion)
plot + geom_tile(aes(x=Var1, y=Var2, fill=Freq)) + scale_x_discrete(name="Actual Class") + scale_y_discrete(name="Predicted Class") + scale_fill_gradient(breaks=seq(from=-.5, to=4, by=.2)) + labs(fill="Normalized\nFrequency")
input.matrix.normalized <- normalize(input.matrix)
colnames(input.matrix.normalized) = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N")
input.matrix.normalized <- normalize(input.matrix)
??normalize
install.packages("recommenderlab")
?normalize
??normalize
library(recommenderlab)
input.matrix <- data.matrix(input)
input.matrix.normalized <- normalize(input.matrix)
?normalize
normalize(input.matrix)
class(input.matrix)
class(input.matrix) <- "realRatingMatrix"
input.matrix.normalized <- normalize(input.matrix)
input.matrix <- data.matrix(input)
heatmap(cm$table, Rowv=NA, Colv=NA, verbose=F, col=topo.colors(100))
heatmap.2(cm$table, col=redgreen(75),
key=TRUE, symkey=FALSE, density.info="none", trace="none")#, cexRow=0.5)
cm$table
names(cm$table)
str(cm$table)
?heatmap2
fourfoldplot(cm$table, color = c("#CC6666", "#99CC99"),
conf.level = 0, margin = 1, main = "Confusion Matrix")
?plot.confusion
??plot.confusion
??confusion
install.packages("mlearning")
library(mlearning)
?confusion
confusion(pred.nn.fact,true.nn.fact)
conf <- confusion(pred.nn.fact,true.nn.fact)
plot(conf)
prior(conf) <- 100
# The above rescales the confusion matrix such that columns sum to 100.
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(confonf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = sub('^0$', '', round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
prior(conf) <- 100
# The above rescales the confusion matrix such that columns sum to 100.
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(confonf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = sub('^0$', '', round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
prior(conf) <- 100
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(confonf)
x <- x.orig <- unclass(conf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = sub('^0$', '', round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
conf <- confusion(pred.nn.fact,true.nn.fact)
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(conf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = sub('^0$', '', round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
x.orig
log(x + 0.5) * 2.33
x[x < 0]
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(conf)
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = sub('^0$', '', round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
# The above rescales the confusion matrix such that columns sum to 100.
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(conf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = sub('^0$', '', round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
x.orig
c(x.orig)
round(c(x.orig), 0)
?sub
# The above rescales the confusion matrix such that columns sum to 100.
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(conf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = round(c(x.orig), 0)))
box(lwd=2)
par(opar) # reset par
round(c(x.orig), 0)
# The above rescales the confusion matrix such that columns sum to 100.
opar <- par(mar=c(5.1, 6.1, 2, 2))
x <- x.orig <- unclass(conf)
x <- log(x + 0.5) * 2.33
x[x < 0] <- NA
x[x > 10] <- 10
diag(x) <- -diag(x)
image(1:ncol(x), 1:ncol(x),
-(x[, nrow(x):1]), xlab='Actual', ylab='',
col=colorRampPalette(c(hsv(h = 0, s = 0.9, v = 0.9, alpha = 1),
hsv(h = 0, s = 0, v = 0.9, alpha = 1),
hsv(h = 2/6, s = 0.9, v = 0.9, alpha = 1)))(41),
xaxt='n', yaxt='n', zlim=c(-10, 10))
axis(1, at=1:ncol(x), labels=colnames(x), cex.axis=0.8)
axis(2, at=ncol(x):1, labels=colnames(x), las=1, cex.axis=0.8)
title(ylab='Predicted', line=4.5)
abline(h = 0:ncol(x) + 0.5, col = 'gray')
abline(v = 0:ncol(x) + 0.5, col = 'gray')
text(1:6, rep(6:1, each=6),
labels = round(c(x.orig), 0))
box(lwd=2)
par(opar) # reset par
pr.lm
# Using the iris dataset. It's flowers!
data("iris")
data <- iris
apply(data,2,function(x) sum(is.na(x)))
# Train-test random splitting for linear model
index <- sample(1:nrow(data),round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
# Fitting linear model
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
summary(lm.fit)
# Predicted data from lm
pr.lm <- predict(lm.fit,test)
# Test MSE
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
pr.lm
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
summary(lm.fit)
pr.lm <- predict(lm.fit,test)
tedt
test
test$Species
pr.lm
MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)
MSE.lm
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial)#
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
test
test[1:4]
pr.lm <- predict(lm.fit,test[1:4])
pr.lm
summary(lm.fit)
summary(pr.lm)
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
summary(lm.fit)
class(data$Species)
summary(lm.fit)
?glm
lm.fit <- glm(Species ~ . , data=train,family=quasi,control = list(maxit = 50))
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
?predict
pr.lm <- predict(lm.fit, newdata = test[1:4], type="response")
pr.lm
pr.lm <- predict(lm.fit, newdata = test[1:4], type="terms")
pr.lm
pr.lm <- predict(lm.fit, newdata = test[1:4], type="link")
pr.lm
data
data$Species <- as.numeric(data$Species)
index <- sample(1:nrow(data),round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
normalize(data$Species)
x <- data$Species
normalized = (x-min(x))/(max(x)-min(x))
normalized
data$Species <- normalized
index <- sample(1:nrow(data),round(0.75*nrow(data)))
train <- data[index,]
test <- data[-index,]
lm.fit <- glm(Species ~ . , data=train,family=quasibinomial,control = list(maxit = 50))
summary(lm.fit)
pr.lm <- predict(lm.fit, newdata = test[1:4], type="link")
pr.lm
pr.lm <- predict(lm.fit, newdata = test[1:4], type="response")
pr.lm
pr.lm <- predict(lm.fit, newdata = test[1:4], type="response") * 3
pr.lm
round(pr.lm)
pr.lm <- round(pr.lm)
test$medv
test$Species
pr.lm
MSE.lm <- sum((pr.lm - test$Species)^2)/nrow(test)
MSE.lm <- sum((pr.lm - test$Species)^2)/nrow(test)
MSE
MSE.lm <- sum((pr.lm - test$Species)^2)/nrow(test)
MSE.lm
MSE.nn
test.r
pr.lm <- predict(lm.fit, newdata = test[1:4], type="response") * 3
pr.lm
pr.lm <- predict(lm.fit, newdata = test[1:4], type="response")
pr.lm
pr.lm <- predict(lm.fit, newdata = test[1:4], type="link")
pr.lm
library(scatterD3)
?scatterD3
scatterD3(x = pca_data[,"PC1"], y = pca_data[,"PC2"])
setwd("/home/nmerwin/Documents/IGPProject/ImageAnalysis-IGP/D3")
data <- read.csv(list.files()[1],header = FALSE)
nhood5 <- data[grepl("nhood_5", data[,1]),]
nhood10 <- data[grepl("nhood_10", data[,1]),]
nhood20 <- data[grepl("nhood_20", data[,1]),]
formatted <- cbind(nhood5[,1],nhood5[,-1], nhood10[,-1], nhood20[-1])
HD <- grepl("q43",formatted[,1])
treated <- grepl("kinetin",formatted[,1])
formatted <- cbind(HD,treated,formatted)
haraNames <- c("Angular Second Moment", "Contrast","Inverse Difference Moment","Entropy", "X-Mean","Y-Mean","X-Standard Deviation", "Y-Standard Deviation", "Correlation","Mean","Variance","Sum Average","Sum Entropy","Difference Entropy","Inertia","Cluster Shade","Cluster Prominence")
nhood10Names <- sapply(haraNames, sub, pattern="^", replacement="10_", simplify=F)
nhood5Names <- sapply(haraNames, sub, pattern="^", replacement="5_", simplify=F)
nhood20Names <- sapply(haraNames, sub, pattern="^", replacement="20_", simplify=F)
allNames <- as.character(c(nhood5Names,nhood10Names,nhood20Names))
length(names(formatted)[4:54])
length(allNames)
names(formatted)[4:54] <- allNames
ir.pca <- prcomp(formatted[,4:54],
center = TRUE,
scale. = TRUE)
pca_data <- data.frame(ir.pca$x)
myGrouping <- function(HD,treated){
if(HD & treated){
return (c("HDTreated"))
}
else if(HD & (!treated)){
return (c("HD"))
}
else if( (!HD) ){
return (c("Healthy"))
}
}
group <- mapply(myGrouping,HD,treated)
group
pca_data <- cbind(group,pca_data)
pca_data
scatterD3(x = pca_data[,"PC1"], y = pca_data[,"PC2"])
?scatterD3
scatterD3(x = pca_data[,"PC1"], y = pca_data[,"PC2"], col_var = pca_data[,"group"])
scatterD3(x = pca_data[,"PC1"], y = pca_data[,"PC2"], col_var = pca_data[,"group"], ellipses=T)
pca_data$PC1
pca_data$PC1 > 5
pca_data$PC1[pca_data$PC1 > 5 ]
